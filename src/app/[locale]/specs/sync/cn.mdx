export const metadata = {
  title: 'Sync',
  description:
    'Firehose 及其他数据同步机制。',
}

# 数据同步

atproto("身份认证传输协议")的主要设计目标之一是在独立的网络服务之间可靠地分发公共内容。即使在大规模情况下,这种数据传输也应该是可信的(加密认证的)且相对低延迟的。同时重要的是,新的参与者可以随时加入网络并"回填"之前的内容。

本节描述了 atproto 中主要的数据同步功能。主要的实时数据同步机制是仓库事件流,通常称为"firehose"。主要的批量数据传输机制是将仓库导出为 CAR 文件。这两种机制可以在"引导"过程中结合使用,从而实现网络的实时同步副本。

<Note>
同步协议的更新版本将于 2025 年初在实时网络中推出。具体详情可查看["Sync v1.1" 提案文档](https://github.com/bluesky-social/proposals/tree/main/0006-sync-iteration)和[更新博客文章](https://docs.bsky.app/blog/relay-sync-updates)。书面规范将很快更新。
</Note>

## 同步原语

如仓库规范中所述,仓库的每次提交都有一个采用 TID 语法的*修订号*。即使账户在主机之间迁移或在网络中有一段不活跃期,同一账户的修订号也必须在提交之间递增。修订号可以用作逻辑时钟来帮助同步单个账户。为简单起见,建议使用当前时间作为每次提交的 TID,包括创建新账户时的初始提交。服务应拒绝或忽略对应于未来时间戳的修订号(超出短暂的模糊时间偏移窗口)。网络服务可以跟踪他们看到的每个账户的提交修订,并使用它来验证同步进度。同步数据的服务可以在对来自相关账户的 API 请求的 HTTP 响应中,在 `Atproto-Repo-Rev` HTTP 响应头中包含最近处理的修订。这使客户端(和用户)能够检测响应是否与实际仓库保持同步,并检测任何同步问题。

## Firehose

仓库事件流(`com.atproto.sync.subscribeRepos`,也称为"firehose")是一个[事件流](/specs/event-stream),它广播仓库更新(`#commit` 事件)、handle 和 DID 文档(`#identity`)以及账户托管状态(`#account`)。PDS 主机为所有本地托管的账户提供单个流。"Relay"是一种网络服务,它订阅一个或多个仓库流(例如,多个 PDS 实例)并将它们聚合到单个组合仓库流中。组合流具有相同的结构和事件类型。聚合了网络中几乎所有 PDS 实例的几乎所有账户的 Relay(可能通过中间 relay)输出"全网"firehose。Relay 通常会镜像并可以重新分发仓库内容,但其核心功能是验证内容并输出统一的 firehose。

在大多数情况下,通过 firehose 同步的仓库数据是自证明的(包含可验证的签名),消费者可以验证内容而无需直接向账户 PDS 实例发出额外请求。服务可以从 firehose 中编辑事件,使下游服务无法感知新内容。

身份和账户信息*不是*自证明的,服务可能需要独立验证。这通常意味着独立的 DID 和 [handle 解析](/specs/handle)。账户托管状态也可能在账户 PDS 主机上进行检查,以消除不同基础设施上托管状态的歧义。

事件消息类型在 `com.atproto.sync.subscribeRepos` Lexicon 模式中声明,并在下面进行了总结。一些字段对所有事件类型都是相同的(除了 `#commit` 事件的 `repo` vs `did`):

- `seq` (整数,必需): 用于确保可靠消费,如事件流中所述
- `did` / `repo`(DID 语法字符串,必需): 与事件关联的账户/身份
- `time` (datetime 语法字符串,必需): 非正式且非权威的事件接收时间估计。中间服务可以决定按原样传递此字段,或更新为当前时间

### `#identity` 事件

表明指示的身份(即 DID 文档或 handle)可能*已*发生更改,并可选地显示当前的 handle 是什么。不指示更改的内容,也不可靠地指示身份的当前状态。

事件字段:

- `seq` (整数,必需): 对所有事件类型都相同
- `did` (DID 语法字符串,必需): 对所有事件类型都相同
- `time` (datetime 语法字符串,必需): 对所有事件类型都相同
- `handle` (handle 语法字符串,可选): 此身份的当前 handle。如果 handle 当前无法正确解析,可能是 `handle.invalid`。

`handle` 字段的存在或缺失并不表示发生更改的是 handle。

语义和预期行为是下游服务应该更新所指示 DID 的任何缓存身份元数据(包括 DID 文档和 handle)。它们可能将缓存标记为过期、立即清除缓存数据或尝试重新解析元数据。

身份事件是按"尽力而为"的方式发出的。DID 文档或 handle 解析状态可能在没有任何 atproto 服务检测到变化的情况下发生变化,在这种情况下不会发出事件。也可能在实际上没有任何变化时冗余地发出事件。

中间服务(例如,relay)可以选择修改或传递身份事件:

- 他们可以用自己解析的结果替换 handle;或始终删除 handle 字段;或始终按原样传递
- 如果他们观察到身份实际上没有改变,他们可以过滤掉身份事件
- 他们可以基于他们独立获知的变化发出身份事件(例如,通过定期重新验证 handle)

### `#account` 事件

表示事件发出服务的[账户托管状态](/specs/account)可能已发生变化,并指明新的状态。例如,这可能是由于账户的创建、删除或临时暂停引起的。事件描述的是当前的托管状态,而不是发生了什么变化。

事件字段:

- `seq` (整数,必需): 对所有事件类型都相同
- `did` (DID 语法字符串,必需): 对所有事件类型都相同
- `time` (datetime 语法字符串,必需): 对所有事件类型都相同
- `active` (布尔值,必需): 仓库当前是否可用且可以重新分发
- `status` (字符串,可选): 更详细描述账户状态的状态码。已知值包括:
  - `takendown`: 由于违反条款或政策,服务提供商无限期删除仓库
  - `suspended`: `takedown` 的临时或有时限变体
  - `deleted`: 账户已被停用,可能是永久性的
  - `deactivated`: 账户自行临时或无限期删除所有公开数据

对于重新分发账户数据的任何服务,事件描述的是该服务上的新状态,并在该上下文中具有权威性。换句话说,对于仓库主机和镜像来说,该事件是逐跳传递的。

更多详细信息请参阅账户托管规范。

### `#commit` 事件

此事件表示指定账户的仓库有新的提交。事件通常包含仓库数据的"差异",以 CAR 切片的形式呈现。有关"差异"和 CAR 文件格式的详细信息,请参阅[仓库规范](/specs/repository)。

关于仓库差异的更多详细信息,请参阅仓库规范。

事件字段:

- `seq` (整数,必需): 对所有事件类型都相同
- `repo` (DID 语法字符串,必需): 与所有其他事件类型的 `did` 相同
- `time` (datetime 语法字符串,必需): 对所有事件类型都相同
- `rev` (TID 语法字符串,必需): 提交的修订号。必须与提交块本身中的 `rev` 匹配
- `since` (TID 语法字符串,可为空): 表示仓库差异包含与之不同的前一个提交的 `rev`
- `commit` (cid-link,必需): 提交对象的 CID(在 `blocks` 中)
- `tooBig` (布尔值,必需): 如果为 true,表示仓库差异太大,`blocks`、`ops` 和完整 `blobs` 不会全部包含
- `blocks` (字节,必需): 对应仓库差异的 CAR "切片"。必须始终包含提交对象
- `ops` (对象数组,必需): 此提交中记录级操作的列表:创建、更新、删除的具体记录
- `blobs` (cid-link 数组,必需): 此提交中记录引用的新 blob(通过 CID)集合

当账户仓库发生变化时会广播提交事件。提交可以是"空的",意味着没有实际的记录内容更改,只是增加了 `rev`。它们可以包含单个记录更新或多个更新。只有提交对象、记录块和 MST 树节点是经过认证(签名)的:而 `since`、`ops`、`blobs` 和 `tooBig` 字段不是自证明的,理论上可以被操纵,或者不正确或不完整。

如果不包含 `since`,提交应该包含完整的仓库树,或设置 `tooBig` 标志。

如果设置了 `tooBig` 标志,则表示更新的数据量太大,无法在单个流事件消息中序列化。希望维护仓库完整同步副本的下游服务需要单独获取差异,如下所述。

### Firehose 验证最佳实践

完全验证上游事件的服务需要跟踪和检查许多属性。例如,Relay 实例在重新广播之前应该完全验证来自 PDS 实例的内容。

以下是验证规则和行为的总结:

- 服务应该独立解析每个 DID 的身份数据。它们应该忽略没有有效 atproto 身份的账户的 `#commit` 事件(例如,缺少签名密钥、缺少 PDS 服务条目,或 DID 已被移除)
- 直接订阅 PDS 实例的服务应该跟踪每个 DID 的权威 PDS。它们应该记住每个订阅(WebSocket)连接的主机,如果 `#commit` 事件来自与该 DID 当前账户不对应的流,则拒绝这些事件
- 服务应该跟踪每个 DID 的账户托管状态,并忽略非 `active` 事件的 `#commit` 事件
- 服务应使用当前身份数据验证每个 `#commit` 事件的提交签名。如果签名最初验证失败,服务应该刷新身份元数据,以防最近发生更改。应拒绝签名明确无效的事件
- 服务应该拒绝超出合理限制的任何事件消息。对于生产者来说,合理的上限是 5 MB(对于任何事件流消息类型)。`subscribeRepos` Lexicon 还将 `blocks` 限制为一百万字节,将 `ops` 限制为 200 个条目。包含太多数据的提交必须使用 `tooBig` 机制,不过一般应该通过将其拆分为多个较小的提交来避免这种提交
- 服务应验证仓库数据结构是否符合规范。缺少字段、MST 结构不正确或其他协议层违规应导致事件被拒绝
- 服务可能对身份、账户和提交事件应用速率限制,并暂停违反这些限制的账户或上游服务。速率限制也可能应用于恢复模式,例如无效签名导致身份刷新、`tooBig` 事件、缺失或不按顺序的提交等
- 服务应忽略 `rev` 低于或等于该 DID 最近处理的 `rev` 的提交事件,并应拒绝 `rev` 对应于未来时间戳的提交事件(超出几分钟的时钟漂移窗口)
- 服务应检查提交事件中的 `since` 值,如果它与该 DID 之前看到的 `rev` 不一致(参见"可靠同步"中的讨论),则将仓库标记为不同步(类似于 `tooBig` 提交事件)
- 应该验证对记录的具体数据限制。包含损坏或完全无效记录的事件可能被拒绝。例如,记录根本不是 CBOR,或超出正常数据大小限制
- 根据服务的不同,可能会强制执行或忽略更微妙的记录数据验证。例如,记录中嵌入的不受支持的 CID 哈希类型可能会被 Relay 忽略(即使它们违反了 atproto 数据模型),但可能导致 AppView 拒绝记录或提交事件
- 镜像服务(保留仓库数据完整副本)应验证提交差异是否使 MST 树处于完整和有效状态(例如,没有缺失记录、无效的 MST 节点,如果从头重新生成 MST 结构,提交 CID 应该是可重现的)
- Relay(特别是)不应根据 Lexicons 验证记录

## 可靠同步

本节描述了如何可靠地订阅 firehose 并维护网络的现有同步镜像的一些细节。

服务通常应该为所有正在跟踪数据的账户维护一些状态:

- 跟踪已成功处理的最新提交 `rev`
- 保留缓存的身份数据,并使用缓存过期来确保定期重新验证该数据
- 跟踪账户状态

每当收到 `#identity` 事件时都应该清除身份缓存。此外,如果提交签名验证失败,应该刷新身份解析,以防签名密钥已更新但身份缓存尚未更新。

当 firehose 上发出 `tooBig` 事件时,下游服务需要带外获取差异。这通常意味着向账户当前 PDS 主机的 `com.atproto.sync.getRepo` 端点发出 API 请求,包含 `since` 字段。`since` 值应该是该账户最近处理的 `rev` 值,可能与提交事件消息中的 `since` 字段匹配,也可能不匹配。

如果收到的 `#commit` 的 `since` 与该账户最近处理的 `rev` 不匹配,且"较晚"(值更高)服务已处理该账户的最新提交 `rev`,则服务可能需要进行与 `tooBig` 事件相同类型的带外获取。

服务应该跟踪其上游订阅的 `seq` 编号。即使只有单个 Relay 连接,这也应该按上游单独存储,以防将来订阅不同的 Relay(它们将有不同的 `seq` 编号)。

事件可以并发处理,但对于任何给定账户,它们都应该按顺序处理。这可以通过使用仓库 DID 作为分区键来划分多个工作者来实现。

服务可以通过从其他服务(包括 PDS 主机和 Relay 实例)获取仓库 DID 和 `rev` 编号的快照来确认它们正在可靠地消费内容。经过短暂延迟后,可以将这些与服务的当前状态进行比较,以识别 `rev` 编号低于预期的任何账户。然后可以在带外更新这些仓库。

## 引导实时镜像

firehose 可以用于跟踪新数据更新,而仓库导出可以用于快照。实际上将两者结合来引导完整的实时更新镜像可能有点棘手。下面描述了一种方法。

为所有遇到的账户(DID)保持一个同步状态表。状态可以是:

- `dirty`: 此账户或者没有本地仓库数据,或者已经不同步了
- `in-process`: 仓库是"dirty"的,但有后台任务正在处理
- `synchronized`: 已处理仓库的完整副本

首先订阅完整的 firehose。如果账户没有现有的仓库数据,将账户标记为"dirty"。当仓库有新事件进来时,行为取决于仓库状态。如果是"dirty",事件会被忽略。如果状态是"synchronized",事件会立即作为仓库更新处理。如果状态是"in-process",事件会在本地排队。

有一组后台工作线程开始处理“dirty”仓库。首先它们将状态标记为 `in-process`，这样新事件就会被本地排队。然后从 PDS 获取完整的仓库导出（CAR 文件）并进行完整处理。记录仓库导出的提交 `rev`。当完整的仓库导入完成后，工作线程可以开始按顺序处理所有排队的事件，跳过任何 `rev` 低于已处理仓库 `rev` 的事件（与通常行为一致）。当该账户的队列全部处理完毕后，状态可以切换为 `synchronized`，工作线程可以继续处理下一个账户。

经过一段时间后，大多数已知账户将被标记为 `synchronized`，但这只代表网络中最近活跃的账户。接下来可以获取网络中更完整的一组仓库，例如通过对现有大型服务进行 API 查询。任何新识别的账户都可以在服务中标记为 `dirty`，后台工作线程可以开始处理它们。

当所有账户都为 `synchronized` 时，该过程就完成了。在大规模场景下，可能很难实现完美同步：PDS 实例可能会在不同时间宕机，身份可能解析失败，或者无效事件、数据或签名可能出现在网络中。

## 使用与实现指南

不同账户事件期间 firehose 事件排序的具体指南，请参阅[账户生命周期最佳实践指南](/guides/account-lifecycle)。

## 安全注意事项

建议采取通用的资源耗尽攻击缓解措施：事件速率限制、每账户数据配额、数据对象大小和反序列化数据复杂度限制等。

当向未知或不受信任的主机发起网络请求时应格外小心，尤其是这些主机的网络定位器来自不受信任的输入。这包括验证 URL，避免连接到本地或内部主机（包括通过 HTTP 重定向），避免浏览器环境中的 SSRF 等。

为防止流量放大攻击，出站网络请求应按主机进行速率限制。例如，在消费 firehose 时进行身份解析请求，包括 DNS TXT 流量和 DID 解析请求。

## 后续工作

`subscribeRepos` Lexicon 可能会进行调整，移除已弃用字段，即使这会违反 Lexicon 演进规则。

事件流的序列/游标方案可能会迭代，以支持分片、基于时间戳的恢复以及在独立实例之间更容易的故障切换。

协议可能会增加完整认证 firehose 的替代方案。例如，简单的 JSON 序列化、按记录集合类型过滤、省略 MST 节点，以及其他简化开发和减少资源消耗的更改，适用于不需要或不希望完全认证的用例。
